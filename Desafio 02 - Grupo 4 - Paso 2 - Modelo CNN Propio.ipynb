{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELO = \"Propio\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "keras.__version__\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.utils import multi_gpu_model\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1,2,3\"\n",
    "multi_gpu = len(\"0,1,2,3\".split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session():\n",
    "    \"\"\" Construct a modified tf session.\n",
    "    \"\"\"\n",
    "    config = tf.ConfigProto(device_count = {'CPU' :24, 'GPU':4})\n",
    "    config.gpu_options.allow_growth = True\n",
    "    return tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.tensorflow_backend.set_session(get_session())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo Propio CNN (conv2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El directorio de trabajo\n",
    "processDir = './process'\n",
    "\n",
    "# Directorio para entrenamiento, validacion y test\n",
    "train_dir = os.path.join(processDir, 'train')\n",
    "validation_dir = os.path.join(processDir, 'validation')\n",
    "test_dir = os.path.join(processDir, 'test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generador de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14530 images belonging to 120 classes.\n",
      "Found 3025 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,)\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(300, 300),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(300, 300),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "if multi_gpu > 1:\n",
    "  \n",
    "    with tf.device('/cpu:0'):\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Conv2D(32, (3, 3), activation='relu',input_shape=(300, 300, 3)))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(512, activation='relu'))\n",
    "        model.add(layers.Dense(120, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if multi_gpu > 1:\n",
    "    parallel_model = multi_gpu_model(model, gpus=multi_gpu)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_radam import RAdam\n",
    "\n",
    "parallel_model.compile(loss='categorical_crossentropy',\n",
    "                       optimizer=RAdam(total_steps=5000, warmup_proportion=0.1, min_lr=1e-7),\n",
    "                       metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import callbacks\n",
    "\n",
    "callbacks = [callbacks.EarlyStopping(monitor='val_categorical_accuracy', min_delta=0.001, patience=20, restore_best_weights=True, mode='max')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      " 69/100 [===================>..........] - ETA: 23s - loss: 4.7842 - categorical_accuracy: 0.0136"
     ]
    }
   ],
   "source": [
    "history = parallel_model.fit_generator(train_generator,\n",
    "                                       steps_per_epoch=100,\n",
    "                                       epochs=500,\n",
    "                                       validation_data=valid_generator,\n",
    "                                       validation_steps=50,\n",
    "                                       callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# open a file, where you ant to store the data\n",
    "file = open('./models/history_{}.pkl'.format(MODELO), 'wb')\n",
    "\n",
    "# dump information to that file\n",
    "pickle.dump(history.history, file)\n",
    "\n",
    "# close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "acc = history.history['categorical_accuracy']\n",
    "val_acc = history.history['val_categorical_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Train')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation')\n",
    "plt.title('Accuracy: Train, Validation')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Train')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation')\n",
    "plt.title('Loss: Train, Validation')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_model.save('./models/model_{}_RAdam.h5'.format(MODELO))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(300, 300),\n",
    "        batch_size=32,\n",
    "        class_mode=None,\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = parallel_model.predict_generator(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Max Index\n",
    "predicted_class_index=np.argmax(probabilities,axis=1)\n",
    "\n",
    "# Dictionary: Index to Class\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "index_to_labels = dict((v,k) for k,v in test_generator.class_indices.items())\n",
    "\n",
    "# Get List of Predictions\n",
    "predictions = [index_to_labels[ix] for ix in predicted_class_index]\n",
    "\n",
    "# Get Dictionary of Predictions\n",
    "results=pd.DataFrame({\"Filename\":test_generator.filenames,\n",
    "                      \"Predictions\":predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"./models/results_details_{}.csv\".format(MODELO), sep=\"|\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(test_generator.labels, predicted_class_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {}\n",
    "tp_sum, fp_sum = 0, 0\n",
    "\n",
    "for ix, row in enumerate(cm):\n",
    "    \n",
    "    tp = row[ix]\n",
    "    fp = np.sum(row) - tp   \n",
    "    results_dict[ix] = [class_labels[ix],tp,fp,(tp/(tp+fp)*100)]\n",
    "\n",
    "    tp_sum += tp\n",
    "    fp_sum += fp\n",
    "    \n",
    "df_res = pd.DataFrame.from_dict(results_dict, orient=\"index\", columns=[\"Class\",\"True Positive\",\"False Positive\",\"Accuracy\"])\n",
    "\n",
    "print(\"General Accuracy:{:0.2f}\".format(tp_sum/(tp_sum+fp_sum)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.to_csv(\"./models/results_{}.csv\".format(MODELO), sep=\"|\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
