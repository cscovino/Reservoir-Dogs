{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Desafio 02 - Grupo 4 - Paso 2 - Modelo CNN Propio.ipynb",
      "provenance": []
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXq2cVy-xNjG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODELO = \"Propio-500Steps\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fWnfkxVxNjM",
        "colab_type": "code",
        "outputId": "04762064-c73e-4d9a-e777-120241cbc934",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import keras\n",
        "keras.__version__\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras import optimizers\n",
        "from keras.utils import multi_gpu_model\n",
        "from tensorflow.python.client import device_lib"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Llrr5_gBxNjQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1,2,3\"\n",
        "multi_gpu = len(\"0,1,2,3\".split(','))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmF3PAKZxNjT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_session():\n",
        "    \"\"\" Construct a modified tf session.\n",
        "    \"\"\"\n",
        "    config = tf.ConfigProto(device_count = {'CPU' :24, 'GPU':4})\n",
        "    config.gpu_options.allow_growth = True\n",
        "    return tf.Session(config=config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgemVIh_xNjX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keras.backend.tensorflow_backend.set_session(get_session())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "580hCnLMxNja",
        "colab_type": "text"
      },
      "source": [
        "# Modelo Propio CNN (conv2d)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MstnXoXExNjb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# El directorio de trabajo\n",
        "processDir = './process'\n",
        "\n",
        "# Directorio para entrenamiento, validacion y test\n",
        "train_dir = os.path.join(processDir, 'train')\n",
        "validation_dir = os.path.join(processDir, 'validation')\n",
        "test_dir = os.path.join(processDir, 'test')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyoj-mbTxNjd",
        "colab_type": "text"
      },
      "source": [
        "# Generador de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGZqYMBRxNje",
        "colab_type": "code",
        "outputId": "d6b45611-e0a8-4692-8557-642f79cf4ead",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,)\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(300, 300),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(300, 300),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-ec57b68f8b39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         class_mode='categorical')\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m valid_generator = valid_datagen.flow_from_directory(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[1;32m    538\u001b[0m             \u001b[0mfollow_links\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m             \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m         )\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/directory_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './process/train'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7oBzPh6xNji",
        "colab_type": "text"
      },
      "source": [
        "# Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2unFByKVz6cT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJb4aq4qxNjj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "\n",
        "if multi_gpu > 1:\n",
        "  \n",
        "    with tf.device('/cpu:0'):\n",
        "        model = models.Sequential()\n",
        "        model.add(layers.Conv2D(512, (5, 5), activation='relu',input_shape=(300, 300, 3)))\n",
        "        model.add(layers.Conv2D(512, (3, 3), activation='relu'))\n",
        "        model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
        "        model.add(layers.MaxPooling2D((2, 2)))\n",
        "        model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
        "        model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "        model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "        model.add(layers.MaxPooling2D((2, 2)))\n",
        "        model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "        model.add(layers.MaxPooling2D((2, 2)))\n",
        "        model.add(layers.Flatten())\n",
        "        model.add(layers.Dense(512, activation='relu'))\n",
        "        model.add(layers.Dropout(0.1))\n",
        "        model.add(layers.Dense(256, activation='relu'))\n",
        "        model.add(layers.Dropout(0.3))\n",
        "        model.add(layers.Dense(120, activation='softmax'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vE6v74B7xNjm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if multi_gpu > 1:\n",
        "    parallel_model = multi_gpu_model(model, gpus=multi_gpu)   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSSXH-ZExNjo",
        "colab_type": "text"
      },
      "source": [
        "# Optimizador"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBW4apHZxNjp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras_radam import RAdam\n",
        "\n",
        "parallel_model.compile(loss='categorical_crossentropy',\n",
        "                       optimizer=RAdam(total_steps=5000, warmup_proportion=0.1, min_lr=1e-7),\n",
        "                       metrics=['categorical_accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qwu1mzrbxNjr",
        "colab_type": "text"
      },
      "source": [
        "# Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjyCaRejxNjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import callbacks\n",
        "\n",
        "callbacks = [callbacks.EarlyStopping(monitor='val_categorical_accuracy', min_delta=0.001, patience=20, restore_best_weights=True, mode='max')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjLJfWocxNjv",
        "colab_type": "text"
      },
      "source": [
        "# Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Ye8R1sdmxNjw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = parallel_model.fit_generator(train_generator,\n",
        "                                       steps_per_epoch=500,\n",
        "                                       epochs=2000,\n",
        "                                       validation_data=valid_generator,\n",
        "                                       validation_steps=200,\n",
        "                                       callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhyq1QRrxNjz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "# open a file, where you ant to store the data\n",
        "file = open('./models/history_{}.pkl'.format(MODELO), 'wb')\n",
        "\n",
        "# dump information to that file\n",
        "pickle.dump(history.history, file)\n",
        "\n",
        "# close the file\n",
        "file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j177iDMLxNj1",
        "colab_type": "text"
      },
      "source": [
        "# Graficos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liFDv_YXxNj2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline  \n",
        "\n",
        "acc = history.history['categorical_accuracy']\n",
        "val_acc = history.history['val_categorical_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Train')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation')\n",
        "plt.title('Accuracy: Train, Validation')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Train')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation')\n",
        "plt.title('Loss: Train, Validation')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FoBAAIQxNj5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parallel_model.save('./models/model_{}_RAdam.h5'.format(MODELO))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq3ISjFDxNj8",
        "colab_type": "text"
      },
      "source": [
        "# Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRfLa2jexNj9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        target_size=(300, 300),\n",
        "        batch_size=32,\n",
        "        class_mode=None,\n",
        "        shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQZj84zvxNj_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "probabilities = parallel_model.predict_generator(test_generator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJOzdDdxxNkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get Max Index\n",
        "predicted_class_index=np.argmax(probabilities,axis=1)\n",
        "\n",
        "# Dictionary: Index to Class\n",
        "class_labels = list(test_generator.class_indices.keys())\n",
        "index_to_labels = dict((v,k) for k,v in test_generator.class_indices.items())\n",
        "\n",
        "# Get List of Predictions\n",
        "predictions = [index_to_labels[ix] for ix in predicted_class_index]\n",
        "\n",
        "# Get Dictionary of Predictions\n",
        "results=pd.DataFrame({\"Filename\":test_generator.filenames,\n",
        "                      \"Predictions\":predictions})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0aoMA-WxNkJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9Run3JPxNkO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results.to_csv(\"./models/results_details_{}.csv\".format(MODELO), sep=\"|\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tusYSse2xNkR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(test_generator.labels, predicted_class_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLMBcEM-nTVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.Blues):\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBr3Rr4ArCb_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_confusion_matrix(cm, class_labels, 'Confusion Matrix')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8FJ-UBfxNkT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results_dict = {}\n",
        "tp_sum, fp_sum = 0, 0\n",
        "\n",
        "for ix, row in enumerate(cm):\n",
        "    \n",
        "    tp = row[ix]\n",
        "    fp = np.sum(row) - tp   \n",
        "    results_dict[ix] = [class_labels[ix],tp,fp,(tp/(tp+fp)*100)]\n",
        "\n",
        "    tp_sum += tp\n",
        "    fp_sum += fp\n",
        "    \n",
        "df_res = pd.DataFrame.from_dict(results_dict, orient=\"index\", columns=[\"Class\",\"True Positive\",\"False Positive\",\"Accuracy\"])\n",
        "\n",
        "print(\"General Accuracy:{:0.2f}\".format(tp_sum/(tp_sum+fp_sum)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJFtm4oqxNkV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_res.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqeh0EZ-xNkZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_res.to_csv(\"./models/results_{}.csv\".format(MODELO), sep=\"|\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NTzyIruxNkc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}