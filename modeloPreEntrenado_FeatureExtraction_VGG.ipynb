{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.5'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import os, shutil\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction (metodo 1)\n",
    "\n",
    "* Ejecutar base convolucional sobre el dataset.\n",
    "* guardar su salida en una matriz Numpy en el disco.\n",
    "* Usar la informaciÃ³n como entrada para un clasificador densamente conectado e independiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instanciar modelo VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\WORK\\instalacion\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\WORK\\instalacion\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\WORK\\instalacion\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\WORK\\instalacion\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\WORK\\instalacion\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\WORK\\instalacion\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(150, 150, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesar datos\n",
    "* Ejecutar base convolucional sobre dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14530 images belonging to 120 classes.\n",
      "Found 3025 images belonging to 120 classes.\n",
      "Found 3025 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "base_dir = './process'\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,)\n",
    "\n",
    "def extract_features(directory, sample_count):\n",
    "  \n",
    "    features = np.zeros(shape=(sample_count, 4, 4, 512))\n",
    "    labels = np.zeros(shape=(sample_count, 120))\n",
    "    \n",
    "    generator = datagen.flow_from_directory(\n",
    "            directory,\n",
    "            target_size=(150, 150),\n",
    "            batch_size=20,\n",
    "            class_mode='categorical')\n",
    "    \n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        \n",
    "        if i * batch_size >= sample_count:\n",
    "            # Notar que este generador devuelve data indefinidamente en un loop,\n",
    "            # debemos cortarlo con un \"break\" despues de que cada imagen haya sido vista una vez\n",
    "            break\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "train_features, train_labels = extract_features(train_dir, 2000)\n",
    "validation_features, validation_labels = extract_features(validation_dir, 1000)\n",
    "test_features, test_labels = extract_features(test_dir, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplanar los datos de `(samples, 4, 4, 512)` a la forma `(samples, 8192)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.reshape(train_features, (2000, 4 * 4 * 512))\n",
    "validation_features = np.reshape(validation_features, (1000, 4 * 4 * 512))\n",
    "test_features = np.reshape(test_features, (1000, 4 * 4 * 512))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/150\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 5.1100 - acc: 0.0070 - val_loss: 4.7991 - val_acc: 0.0130\n",
      "Epoch 2/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 4.8822 - acc: 0.0110 - val_loss: 4.7887 - val_acc: 0.0060\n",
      "Epoch 3/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 4.8341 - acc: 0.0100 - val_loss: 4.7859 - val_acc: 0.0100\n",
      "Epoch 4/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 4.8076 - acc: 0.0085 - val_loss: 4.7822 - val_acc: 0.0150\n",
      "Epoch 5/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 4.7851 - acc: 0.0130 - val_loss: 4.7828 - val_acc: 0.0120\n",
      "Epoch 6/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 4.7618 - acc: 0.0140 - val_loss: 4.7810 - val_acc: 0.0150\n",
      "Epoch 7/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 4.7432 - acc: 0.0190 - val_loss: 4.7803 - val_acc: 0.0120\n",
      "Epoch 8/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 4.7425 - acc: 0.0210 - val_loss: 4.7770 - val_acc: 0.0200\n",
      "Epoch 9/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 4.7183 - acc: 0.0185 - val_loss: 4.7744 - val_acc: 0.0220\n",
      "Epoch 10/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 4.6887 - acc: 0.0280 - val_loss: 4.7768 - val_acc: 0.0160\n",
      "Epoch 11/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 4.6697 - acc: 0.0285 - val_loss: 4.7753 - val_acc: 0.0120\n",
      "Epoch 12/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 4.6690 - acc: 0.0205 - val_loss: 4.7703 - val_acc: 0.0160\n",
      "Epoch 13/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 4.6478 - acc: 0.0305 - val_loss: 4.7670 - val_acc: 0.0160\n",
      "Epoch 14/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 4.6173 - acc: 0.0370 - val_loss: 4.7623 - val_acc: 0.0160\n",
      "Epoch 15/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 4.6009 - acc: 0.0330 - val_loss: 4.7618 - val_acc: 0.0150\n",
      "Epoch 16/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 4.5773 - acc: 0.0435 - val_loss: 4.7596 - val_acc: 0.0190\n",
      "Epoch 17/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 4.5489 - acc: 0.0435 - val_loss: 4.7582 - val_acc: 0.0160\n",
      "Epoch 18/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 4.5349 - acc: 0.0470 - val_loss: 4.7521 - val_acc: 0.0190\n",
      "Epoch 19/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 4.4976 - acc: 0.0540 - val_loss: 4.7529 - val_acc: 0.0180\n",
      "Epoch 20/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 4.4755 - acc: 0.0650 - val_loss: 4.7495 - val_acc: 0.0170\n",
      "Epoch 21/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 4.4603 - acc: 0.0620 - val_loss: 4.7423 - val_acc: 0.0200\n",
      "Epoch 22/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 4.4177 - acc: 0.0670 - val_loss: 4.7409 - val_acc: 0.0250\n",
      "Epoch 23/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 4.3915 - acc: 0.0730 - val_loss: 4.7332 - val_acc: 0.0250\n",
      "Epoch 24/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 4.3650 - acc: 0.0725 - val_loss: 4.7339 - val_acc: 0.0270\n",
      "Epoch 25/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 4.3387 - acc: 0.0835 - val_loss: 4.7262 - val_acc: 0.0230\n",
      "Epoch 26/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 4.2831 - acc: 0.0940 - val_loss: 4.7219 - val_acc: 0.0280\n",
      "Epoch 27/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 4.2720 - acc: 0.0915 - val_loss: 4.7154 - val_acc: 0.0260\n",
      "Epoch 28/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 4.2377 - acc: 0.1040 - val_loss: 4.7124 - val_acc: 0.0230\n",
      "Epoch 29/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 4.1750 - acc: 0.1140 - val_loss: 4.7072 - val_acc: 0.0270\n",
      "Epoch 30/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 4.1870 - acc: 0.1145 - val_loss: 4.7012 - val_acc: 0.0360\n",
      "Epoch 31/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 4.1442 - acc: 0.1165 - val_loss: 4.6987 - val_acc: 0.0280\n",
      "Epoch 32/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 4.0807 - acc: 0.1360 - val_loss: 4.6904 - val_acc: 0.0350\n",
      "Epoch 33/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 4.0347 - acc: 0.1410 - val_loss: 4.6827 - val_acc: 0.0270\n",
      "Epoch 34/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 4.0173 - acc: 0.1300 - val_loss: 4.6829 - val_acc: 0.0290\n",
      "Epoch 35/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 3.9872 - acc: 0.1515 - val_loss: 4.6750 - val_acc: 0.0290\n",
      "Epoch 36/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 3.9427 - acc: 0.1525 - val_loss: 4.6676 - val_acc: 0.0300\n",
      "Epoch 37/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 3.8921 - acc: 0.1650 - val_loss: 4.6659 - val_acc: 0.0290\n",
      "Epoch 38/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 3.8509 - acc: 0.1685 - val_loss: 4.6631 - val_acc: 0.0320\n",
      "Epoch 39/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 3.8407 - acc: 0.1840 - val_loss: 4.6492 - val_acc: 0.0390\n",
      "Epoch 40/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 3.8052 - acc: 0.1880 - val_loss: 4.6526 - val_acc: 0.0360\n",
      "Epoch 41/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 3.7634 - acc: 0.1885 - val_loss: 4.6472 - val_acc: 0.0340\n",
      "Epoch 42/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 3.7486 - acc: 0.1935 - val_loss: 4.6404 - val_acc: 0.0360\n",
      "Epoch 43/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 3.6725 - acc: 0.2020 - val_loss: 4.6356 - val_acc: 0.0360\n",
      "Epoch 44/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 3.6326 - acc: 0.2135 - val_loss: 4.6227 - val_acc: 0.0380\n",
      "Epoch 45/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 3.6349 - acc: 0.2245 - val_loss: 4.6230 - val_acc: 0.0360\n",
      "Epoch 46/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 3.5728 - acc: 0.2365 - val_loss: 4.6215 - val_acc: 0.0410\n",
      "Epoch 47/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 3.5339 - acc: 0.2310 - val_loss: 4.6151 - val_acc: 0.0420\n",
      "Epoch 48/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 3.5313 - acc: 0.2330 - val_loss: 4.6142 - val_acc: 0.0440\n",
      "Epoch 49/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 3.4753 - acc: 0.2605 - val_loss: 4.6061 - val_acc: 0.0380\n",
      "Epoch 50/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 3.4543 - acc: 0.2580 - val_loss: 4.6071 - val_acc: 0.0360\n",
      "Epoch 51/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 3.4215 - acc: 0.2765 - val_loss: 4.5990 - val_acc: 0.0470\n",
      "Epoch 52/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 3.3540 - acc: 0.2780 - val_loss: 4.5926 - val_acc: 0.0480\n",
      "Epoch 53/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 3.3125 - acc: 0.2930 - val_loss: 4.5888 - val_acc: 0.0430\n",
      "Epoch 54/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 3.2848 - acc: 0.2940 - val_loss: 4.5833 - val_acc: 0.0430\n",
      "Epoch 55/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 3.2611 - acc: 0.3030 - val_loss: 4.5811 - val_acc: 0.0490\n",
      "Epoch 56/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 3.2399 - acc: 0.3020 - val_loss: 4.5732 - val_acc: 0.0450\n",
      "Epoch 57/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 3.1672 - acc: 0.3075 - val_loss: 4.5660 - val_acc: 0.0470\n",
      "Epoch 58/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 3.1517 - acc: 0.3210 - val_loss: 4.5671 - val_acc: 0.0530\n",
      "Epoch 59/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 3.0551 - acc: 0.3425 - val_loss: 4.5601 - val_acc: 0.0530\n",
      "Epoch 60/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 11s 6ms/step - loss: 3.0379 - acc: 0.3490 - val_loss: 4.5579 - val_acc: 0.0460\n",
      "Epoch 61/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 3.0354 - acc: 0.3335 - val_loss: 4.5499 - val_acc: 0.0520\n",
      "Epoch 62/150\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 3.0063 - acc: 0.3490 - val_loss: 4.5530 - val_acc: 0.0500\n",
      "Epoch 63/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 2.9642 - acc: 0.3530 - val_loss: 4.5460 - val_acc: 0.0520\n",
      "Epoch 64/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 2.9275 - acc: 0.3660 - val_loss: 4.5424 - val_acc: 0.0540\n",
      "Epoch 65/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 2.9019 - acc: 0.3755 - val_loss: 4.5372 - val_acc: 0.0520\n",
      "Epoch 66/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 2.8520 - acc: 0.3905 - val_loss: 4.5429 - val_acc: 0.0520\n",
      "Epoch 67/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 2.8375 - acc: 0.3795 - val_loss: 4.5293 - val_acc: 0.0500\n",
      "Epoch 68/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 2.7575 - acc: 0.4285 - val_loss: 4.5287 - val_acc: 0.0520\n",
      "Epoch 69/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 2.7519 - acc: 0.4005 - val_loss: 4.5222 - val_acc: 0.0500\n",
      "Epoch 70/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 2.7116 - acc: 0.4180 - val_loss: 4.5205 - val_acc: 0.0550\n",
      "Epoch 71/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 2.7285 - acc: 0.4085 - val_loss: 4.5181 - val_acc: 0.0510\n",
      "Epoch 72/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 2.6622 - acc: 0.4300 - val_loss: 4.5164 - val_acc: 0.0530\n",
      "Epoch 73/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 2.6131 - acc: 0.4465 - val_loss: 4.5098 - val_acc: 0.0510\n",
      "Epoch 74/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 2.5985 - acc: 0.4480 - val_loss: 4.5122 - val_acc: 0.0580\n",
      "Epoch 75/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 2.5832 - acc: 0.4450 - val_loss: 4.5113 - val_acc: 0.0540\n",
      "Epoch 76/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 2.4921 - acc: 0.4800 - val_loss: 4.5035 - val_acc: 0.0560\n",
      "Epoch 77/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 2.4556 - acc: 0.4695 - val_loss: 4.4986 - val_acc: 0.0530\n",
      "Epoch 78/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 2.4697 - acc: 0.4805 - val_loss: 4.4958 - val_acc: 0.0550\n",
      "Epoch 79/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 2.4286 - acc: 0.4855 - val_loss: 4.4962 - val_acc: 0.0540\n",
      "Epoch 80/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 2.3422 - acc: 0.5140 - val_loss: 4.4938 - val_acc: 0.0550\n",
      "Epoch 81/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 2.3883 - acc: 0.4895 - val_loss: 4.4883 - val_acc: 0.0510\n",
      "Epoch 82/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 2.3272 - acc: 0.5135 - val_loss: 4.4871 - val_acc: 0.0520\n",
      "Epoch 83/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 2.2915 - acc: 0.5085 - val_loss: 4.4884 - val_acc: 0.0530\n",
      "Epoch 84/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 2.2513 - acc: 0.5285 - val_loss: 4.4895 - val_acc: 0.0520\n",
      "Epoch 85/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 2.2220 - acc: 0.5315 - val_loss: 4.4887 - val_acc: 0.0490\n",
      "Epoch 86/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 2.1694 - acc: 0.5460 - val_loss: 4.4821 - val_acc: 0.0500\n",
      "Epoch 87/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 2.1736 - acc: 0.5375 - val_loss: 4.4777 - val_acc: 0.0510\n",
      "Epoch 88/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 2.1562 - acc: 0.5525 - val_loss: 4.4790 - val_acc: 0.0550\n",
      "Epoch 89/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 2.1169 - acc: 0.5490 - val_loss: 4.4788 - val_acc: 0.0490\n",
      "Epoch 90/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 2.0803 - acc: 0.5700 - val_loss: 4.4752 - val_acc: 0.0550\n",
      "Epoch 91/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 2.0635 - acc: 0.5710 - val_loss: 4.4788 - val_acc: 0.0540\n",
      "Epoch 92/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 2.0569 - acc: 0.5760 - val_loss: 4.4784 - val_acc: 0.0570\n",
      "Epoch 93/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.9353 - acc: 0.6010 - val_loss: 4.4769 - val_acc: 0.0550\n",
      "Epoch 94/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.9674 - acc: 0.5940 - val_loss: 4.4703 - val_acc: 0.0580\n",
      "Epoch 95/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.9949 - acc: 0.5955 - val_loss: 4.4707 - val_acc: 0.0500\n",
      "Epoch 96/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.9459 - acc: 0.5970 - val_loss: 4.4731 - val_acc: 0.0560\n",
      "Epoch 97/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.8678 - acc: 0.6205 - val_loss: 4.4680 - val_acc: 0.0480\n",
      "Epoch 98/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.8488 - acc: 0.6240 - val_loss: 4.4638 - val_acc: 0.0530\n",
      "Epoch 99/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.8515 - acc: 0.6275 - val_loss: 4.4672 - val_acc: 0.0540\n",
      "Epoch 100/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.8260 - acc: 0.6370 - val_loss: 4.4677 - val_acc: 0.0510\n",
      "Epoch 101/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.7813 - acc: 0.6445 - val_loss: 4.4609 - val_acc: 0.0530\n",
      "Epoch 102/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.7408 - acc: 0.6440 - val_loss: 4.4621 - val_acc: 0.0490\n",
      "Epoch 103/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.7311 - acc: 0.6480 - val_loss: 4.4598 - val_acc: 0.0530\n",
      "Epoch 104/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.7021 - acc: 0.6500 - val_loss: 4.4654 - val_acc: 0.0530\n",
      "Epoch 105/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.6622 - acc: 0.6710 - val_loss: 4.4630 - val_acc: 0.0570\n",
      "Epoch 106/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.6647 - acc: 0.6805 - val_loss: 4.4539 - val_acc: 0.0570\n",
      "Epoch 107/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.6520 - acc: 0.6735 - val_loss: 4.4600 - val_acc: 0.0510\n",
      "Epoch 108/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.6165 - acc: 0.6775 - val_loss: 4.4546 - val_acc: 0.0530\n",
      "Epoch 109/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.5990 - acc: 0.6880 - val_loss: 4.4621 - val_acc: 0.0490\n",
      "Epoch 110/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.5671 - acc: 0.6990 - val_loss: 4.4568 - val_acc: 0.0590\n",
      "Epoch 111/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.5144 - acc: 0.6980 - val_loss: 4.4645 - val_acc: 0.0550\n",
      "Epoch 112/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.5012 - acc: 0.6950 - val_loss: 4.4594 - val_acc: 0.0520\n",
      "Epoch 113/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.5332 - acc: 0.6820 - val_loss: 4.4654 - val_acc: 0.0560\n",
      "Epoch 114/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.4825 - acc: 0.7120 - val_loss: 4.4641 - val_acc: 0.0590\n",
      "Epoch 115/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.4405 - acc: 0.7140 - val_loss: 4.4740 - val_acc: 0.0570\n",
      "Epoch 116/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.4039 - acc: 0.7185 - val_loss: 4.4621 - val_acc: 0.0610\n",
      "Epoch 117/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.4022 - acc: 0.7385 - val_loss: 4.4570 - val_acc: 0.0590\n",
      "Epoch 118/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.4224 - acc: 0.7185 - val_loss: 4.4649 - val_acc: 0.0570\n",
      "Epoch 119/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.3533 - acc: 0.7610 - val_loss: 4.4680 - val_acc: 0.0590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.3784 - acc: 0.7265 - val_loss: 4.4663 - val_acc: 0.0610\n",
      "Epoch 121/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.3593 - acc: 0.7340 - val_loss: 4.4666 - val_acc: 0.0590\n",
      "Epoch 122/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.3367 - acc: 0.7530 - val_loss: 4.4691 - val_acc: 0.0610\n",
      "Epoch 123/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.3063 - acc: 0.7525 - val_loss: 4.4643 - val_acc: 0.0550\n",
      "Epoch 124/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.2584 - acc: 0.7640 - val_loss: 4.4671 - val_acc: 0.0540\n",
      "Epoch 125/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.2503 - acc: 0.7640 - val_loss: 4.4679 - val_acc: 0.0590\n",
      "Epoch 126/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.2310 - acc: 0.7750 - val_loss: 4.4701 - val_acc: 0.0620\n",
      "Epoch 127/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.2373 - acc: 0.7685 - val_loss: 4.4677 - val_acc: 0.0580\n",
      "Epoch 128/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.1998 - acc: 0.7795 - val_loss: 4.4699 - val_acc: 0.0570\n",
      "Epoch 129/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.2018 - acc: 0.7770 - val_loss: 4.4654 - val_acc: 0.0600\n",
      "Epoch 130/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.1641 - acc: 0.7800 - val_loss: 4.4689 - val_acc: 0.0600\n",
      "Epoch 131/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.1463 - acc: 0.7890 - val_loss: 4.4619 - val_acc: 0.0630\n",
      "Epoch 132/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.1139 - acc: 0.7990 - val_loss: 4.4711 - val_acc: 0.0560\n",
      "Epoch 133/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.1072 - acc: 0.8000 - val_loss: 4.4729 - val_acc: 0.0630\n",
      "Epoch 134/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.1025 - acc: 0.7950 - val_loss: 4.4836 - val_acc: 0.0530\n",
      "Epoch 135/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.0544 - acc: 0.8065 - val_loss: 4.4743 - val_acc: 0.0550\n",
      "Epoch 136/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.0462 - acc: 0.8055 - val_loss: 4.4754 - val_acc: 0.0570\n",
      "Epoch 137/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.0388 - acc: 0.8080 - val_loss: 4.4731 - val_acc: 0.0590\n",
      "Epoch 138/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.0393 - acc: 0.8145 - val_loss: 4.4782 - val_acc: 0.0610\n",
      "Epoch 139/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 0.9999 - acc: 0.8290 - val_loss: 4.4819 - val_acc: 0.0570\n",
      "Epoch 140/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 1.0104 - acc: 0.8215 - val_loss: 4.4807 - val_acc: 0.0600\n",
      "Epoch 141/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 0.9937 - acc: 0.8235 - val_loss: 4.4812 - val_acc: 0.0580\n",
      "Epoch 142/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 0.9541 - acc: 0.8310 - val_loss: 4.4837 - val_acc: 0.0640\n",
      "Epoch 143/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 0.9229 - acc: 0.8330 - val_loss: 4.4879 - val_acc: 0.0610\n",
      "Epoch 144/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 0.9210 - acc: 0.8355 - val_loss: 4.4918 - val_acc: 0.0540\n",
      "Epoch 145/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 0.9163 - acc: 0.8410 - val_loss: 4.4861 - val_acc: 0.0620\n",
      "Epoch 146/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 0.9242 - acc: 0.8360 - val_loss: 4.4853 - val_acc: 0.0540\n",
      "Epoch 147/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 0.9061 - acc: 0.8490 - val_loss: 4.4915 - val_acc: 0.0590\n",
      "Epoch 148/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 0.8670 - acc: 0.8475 - val_loss: 4.4955 - val_acc: 0.0610\n",
      "Epoch 149/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 0.8683 - acc: 0.8515 - val_loss: 4.4950 - val_acc: 0.0620\n",
      "Epoch 150/150\n",
      "2000/2000 [==============================] - 11s 6ms/step - loss: 0.8524 - acc: 0.8520 - val_loss: 4.4915 - val_acc: 0.0630\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(512, activation='relu', input_dim=4 * 4 * 512))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(120, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(lr=2e-5),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(\n",
    "        train_features, \n",
    "        train_labels,\n",
    "        epochs=150,\n",
    "        batch_size=20,\n",
    "        validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction (metodo 2)\n",
    "* Extender el modelo agregando capas densas en la parte superior\n",
    "* Entrenar toda la red."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(120, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 120)               30840     \n",
      "=================================================================\n",
      "Total params: 16,842,936\n",
      "Trainable params: 2,128,248\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definir como no entrenable la base convolucional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14530 images belonging to 120 classes.\n",
      "Found 3025 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compila modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-8c1a8a6f98a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m       \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m       \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m       verbose=2)\n\u001b[0m",
      "\u001b[1;32mD:\\WORK\\instalacion\\anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\WORK\\instalacion\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1656\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1657\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1658\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1659\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1660\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\WORK\\instalacion\\anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    213\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    214\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\WORK\\instalacion\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1447\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1448\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1449\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1450\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\WORK\\instalacion\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2977\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2979\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2980\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\WORK\\instalacion\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2936\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2937\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2938\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\WORK\\instalacion\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=30,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50,\n",
    "      verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Agregar la red personalizada sobre una red base ya entrenada.\n",
    "* Congelar la red base.\n",
    "* Entrenar la parte que nueva.\n",
    "* Descongelar algunas capas en la red base.\n",
    "* Entrenar conjuntamente estas capas y la parte que nueva.\n",
    "\n",
    "Hemos completado los primeros 3 pasos cuando realizamos feature extraction.\n",
    "Avancemos con el 4Âº paso: descongelaremos nuestra conv_base y luego congelaremos capas individuales dentro de ella."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurar capas\n",
    "\n",
    "* Se marca como entrenables de la capa `block5_conv1`en adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = True\n",
    "\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'block5_conv1':\n",
    "        set_trainable = True\n",
    "    layer.trainable = set_trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1 False\n",
      "block1_conv1 False\n",
      "block1_conv2 False\n",
      "block1_pool False\n",
      "block2_conv1 False\n",
      "block2_conv2 False\n",
      "block2_pool False\n",
      "block3_conv1 False\n",
      "block3_conv2 False\n",
      "block3_conv3 False\n",
      "block3_pool False\n",
      "block4_conv1 False\n",
      "block4_conv2 False\n",
      "block4_conv3 False\n",
      "block4_pool False\n",
      "block5_conv1 True\n",
      "block5_conv2 True\n",
      "block5_conv3 True\n",
      "block5_pool True\n"
     ]
    }
   ],
   "source": [
    "# DespuÃ©s de modificar el atributo trainable\n",
    "for layer in conv_base.layers:\n",
    "  print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=30,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50,\n",
    "      verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
